{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "\n",
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "`KEYWORDS = ['python', 'парсинг']`\n",
    "\n",
    " Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы). \n",
    " \n",
    "В итоге должен формироваться датафрейм вида: `<дата> - <заголовок> - <ссылка>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.  \n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: `<дата> - <заголовок> - <ссылка> - <текст_статьи>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HABR_URL = 'https://habr.com/ru/all/'\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "DATA_FRAME = {\"date\": [], \"title\": [], \"link\": [], \"text\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(HABR_URL)\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "posts = soup.find_all('article', class_='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_text(link):\n",
    "    req = requests.get(link)\n",
    "    time.sleep(0.3)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    text = soup.find('div', {'id': 'post-content-body'}).get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_posts(post):\n",
    "    full_link = post.find('a', class_='post__title_link')\n",
    "    link = full_link.get('href')\n",
    "    title = full_link.get_text()\n",
    "    date = post.find('span', class_='post__time')\n",
    "    text = get_post_text(link)\n",
    "    \n",
    "    if any([kwd in text.lower() for kwd in KEYWORDS]):\n",
    "        DATA_FRAME[\"link\"].append(link)\n",
    "        DATA_FRAME[\"title\"].append(title)\n",
    "        DATA_FRAME[\"date\"].append(date)\n",
    "        DATA_FRAME[\"text\"].append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in posts:\n",
    "    filter_posts(post)\n",
    "        \n",
    "post_df = pd.DataFrame(DATA_FRAME)\n",
    "\n",
    "post_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: `<почта> - <дата утечки> - <источник утечки> - <описание утечки>`  \n",
    "\n",
    "**Подсказка**: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = [\"xxx@x.ru\", \"yyy@y.com\"]\n",
    "url = \"https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Accept': '*/*', \n",
    "        'Accept-Encoding':'gzip, deflate, br',\n",
    "        'Content-Length':'31',\n",
    "        'Content-Type':'application/json',\n",
    "        'Host':'identityprotection.avast.com',\n",
    "        'User-Agent':'PostmanRuntime/7.26.10',\n",
    "        'Connection':'keep-alive',\n",
    "        'Vaar-Header-App-Build-Version':'1.0.0',\n",
    "        'Vaar-Header-App-Product-Name':'hackcheck-web-avast',\n",
    "        'Vaar-Version':'0'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns=('email', 'leak_date', 'leak_source', 'description'))\n",
    "\n",
    "for email in EMAIL:\n",
    "    payload = {\"emailAddresses\":[email]}\n",
    "    res = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    try:\n",
    "        result = pd.DataFrame(res.json()['breaches'])     \n",
    "        if len(result.index)==0:\n",
    "            print('Почта '+email+' не взломана')\n",
    "\n",
    "        for item in result:\n",
    "            df = pd.DataFrame(\n",
    "                {\"email\": [email],\n",
    "                \"leak_date\": [result[item]['publishDate']],\n",
    "                \"leak_source\": [result[item]['site']],\n",
    "                \"description\": [result['description']]})\n",
    "            res_df = res_df.append(df)\n",
    "        \n",
    "    except:\n",
    "        print('Для почты '+email+' cайт выдал Captcha.')\n",
    "        \n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.  \n",
    "Документация к API VK: https://vk.com/dev/methods\n",
    ", вам поможет метод [wall.get](https://vk.com/dev/wall.get)  \n",
    "```\n",
    "GROUP = 'netology'  \n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ  \n",
    "```\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: `<дата поста> - <текст поста>`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
